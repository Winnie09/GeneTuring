{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74774fcd-fdd7-48fc-a6f7-5ae9a18f7cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=gene&retmax=5&retmode=json&sort=relevance&term=LMP10\n",
      "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=gene&retmax=5&retmode=json&id=19171,5699,8138\n",
      "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?db=snp&retmax=10&retmode=json&id=1217074595\n",
      "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=omim&retmax=20&retmode=json&sort=relevance&term=Meesmann+corneal+dystrophy\n",
      "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?db=omim&retmax=20&retmode=json&id=618767,601687,300778,148043,122100\n",
      "https://blast.ncbi.nlm.nih.gov/blast/Blast.cgi?CMD=Put&PROGRAM=blastn&MEGABLAST=on&DATABASE=nt&FORMAT_TYPE=XML&QUERY=ATTCTGCCTTTAGTAATTTGATGACAGAGACTTCTTGGGAACCACAGCCAGGGAGCCACCCTTTACTCCACCAACAGGTGGCTTATATCCAATCTGAGAAAGAAAGAAAAAAAAAAAAGTATTTCTCT&HITLIST_SIZE=5\n",
      "https://blast.ncbi.nlm.nih.gov/blast/Blast.cgi?CMD=Get&FORMAT_TYPE=Text&RID=87KS399U014\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import openai\n",
    "from funcs import get_prompt_header, openai_request, safe_api_call\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = openai.OpenAI(api_key='YOUR_KEY') # Please put your openAI key here\n",
    "\n",
    "# str_mask is a string of six 0/1 marking whether a in-context learning component is used \n",
    "# six digits correspond to Dc. 1-2, Dm. 1-4\n",
    "str_mask = '111111' # full model is 111111, slim model is 001001\n",
    "mask = [bool(int(x)) for x in str_mask]\n",
    "prompt = get_prompt_header(mask)\n",
    "\n",
    "# rough number of chars for truncating \n",
    "cut_length = 16000\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "df = pd.read_csv('Q&A_dataset.csv')\n",
    "modules = df['Module'].unique()\n",
    "\n",
    "# Calculate total progress\n",
    "total_questions = len(df)\n",
    "total_attempts = total_questions * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baea83c-bd4a-404c-b081-0d78120cef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main progress bar\n",
    "with tqdm(total=total_attempts, desc=\"Processing all questions\", unit=\"attempts\") as pbar:\n",
    "    \n",
    "    # Process each module separately\n",
    "    for module in modules:\n",
    "        # Filter dataframe for current module\n",
    "        module_df = df[df['Module'] == module].copy()\n",
    "        \n",
    "        # Prepare results list for this module\n",
    "        module_results = []\n",
    "        \n",
    "        # Process each question in the current module\n",
    "        for idx, row in module_df.iterrows():\n",
    "            question = row['Question']\n",
    "            model = row['Model']\n",
    "            goldstandard = row['Goldstandard']\n",
    "            \n",
    "            # Ask the same question 3 times\n",
    "            answers = []\n",
    "            \n",
    "            for attempt in range(3):\n",
    "                pbar.set_description(f\"Module: {module} | Q{len(module_results)+1}/{len(module_df)} | Attempt {attempt+1}/3\")\n",
    "                \n",
    "                q_prompt = prompt + f'Question: {question}\\n'  \n",
    "                \n",
    "                # Save the prompting logs\n",
    "                prompts = []\n",
    "                # Record API call times\n",
    "                num_calls = 0\n",
    "                final_answer = None\n",
    "                \n",
    "                while True:\n",
    "                    if len(q_prompt) > cut_length:  # Make sure 'cut_length' is defined\n",
    "                        # Truncate from the start\n",
    "                        q_prompt = q_prompt[len(q_prompt) - cut_length:]\n",
    "                    \n",
    "                    # Use the improved OpenAI request function\n",
    "                    text = openai_request(q_prompt, logger, client)\n",
    "                    \n",
    "                    # Handle error responses\n",
    "                    if text in ['timeoutError', 'rateLimitError', 'lengthError'] or text.startswith('unexpectedError'):\n",
    "                        final_answer = text\n",
    "                        break\n",
    "                    \n",
    "                    num_calls += 1\n",
    "                    prompts.append([q_prompt, text])\n",
    "                    \n",
    "                    # Look for URLs in the response\n",
    "                    url_regex = r'\\[(https?://[^\\[\\]]+)\\]'\n",
    "                    matches = re.findall(url_regex, text)\n",
    "                    \n",
    "                    if matches:\n",
    "                        url = matches[0]\n",
    "                        \n",
    "                        # Wait for BLAST operations\n",
    "                        if 'blast' in url and 'Get' in url: \n",
    "                            time.sleep(30)\n",
    "                        \n",
    "                        # Use safe API call function\n",
    "                        call = safe_api_call(url)\n",
    "                        \n",
    "                        # Handle BLAST RID extraction\n",
    "                        if 'blast' in url and 'Put' in url and isinstance(call, bytes):\n",
    "                            try:\n",
    "                                rid = re.search('RID = (.*)\\n', call.decode('utf-8')).group(1)\n",
    "                                call = rid\n",
    "                            except:\n",
    "                                call = \"BLAST_ERROR: Could not extract RID\"\n",
    "                        \n",
    "                        # Handle bytes response\n",
    "                        if isinstance(call, bytes):\n",
    "                            call = call.decode('utf-8', errors='ignore')\n",
    "                        \n",
    "                        # Limit response length\n",
    "                        if len(str(call)) > 20000:\n",
    "                            call = str(call)[:20000]\n",
    "                        \n",
    "                        q_prompt = f'{q_prompt}{text}->[{call}]\\n'\n",
    "                    else:\n",
    "                        final_answer = text\n",
    "                        break\n",
    "                    \n",
    "                    # Prevent infinite loops\n",
    "                    if num_calls >= 10:\n",
    "                        final_answer = 'numError'\n",
    "                        break\n",
    "                \n",
    "                answers.append(final_answer)\n",
    "                pbar.update(1)\n",
    "                \n",
    "                # Add a delay between attempts\n",
    "                time.sleep(1)\n",
    "            \n",
    "            # Add results for this question\n",
    "            module_results.append({\n",
    "                'Model': model,\n",
    "                'Module': module,\n",
    "                'Question': question,\n",
    "                'Goldstandard': goldstandard,\n",
    "                'Answer1': answers[0],\n",
    "                'Answer2': answers[1],\n",
    "                'Answer3': answers[2]\n",
    "            })\n",
    "            \n",
    "            # Save progress after each question (in case of interruption)\n",
    "            module_results_df = pd.DataFrame(module_results)\n",
    "            filename = f\"{module}_results.csv\"\n",
    "            module_results_df.to_csv(filename, index=False)\n",
    "            logger.info(f\"Saved progress: {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
